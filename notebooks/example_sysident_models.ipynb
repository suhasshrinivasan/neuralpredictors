{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "# System Identification Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook describes how to build system identification models for any target distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/sinzlab/nnsysident.git@ICLR2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataport not available, will only be able to load data locally\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch import nn\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from nnsysident.datasets.mouse_loaders import static_loaders\n",
    "from nnsysident.utility.data_helpers import extract_data_key\n",
    "from nnsysident.utility.measures import get_model_performance\n",
    "from nnsysident.utility.data_helpers import get_dims_for_loader_dict\n",
    "\n",
    "random_seed = 27121992\n",
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "paths = ['./data/static20457-5-9-preproc0']\n",
    "\n",
    "data_key = extract_data_key(paths[0])\n",
    "\n",
    "dataset_config = {'paths': paths,\n",
    "                  'batch_size': 64,\n",
    "                  'seed': random_seed,\n",
    "                  'loader_outputs': [\"images\", \"responses\"],\n",
    "                  'normalize': True,\n",
    "                  'exclude': [\"images\"],\n",
    "                  \"cuda\": True if device==\"cuda\" else False\n",
    "                  }\n",
    "\n",
    "dataloaders = static_loaders(**dataset_config)\n",
    "\n",
    "session_shape_dict = get_dims_for_loader_dict(dataloaders[\"train\"])\n",
    "n_neurons_dict = {k: v[\"responses\"][1] for k, v in session_shape_dict.items()}\n",
    "in_shapes_dict = {k: v[\"images\"] for k, v in session_shape_dict.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from neuralpredictors.layers.cores import Stacked2dCore\n",
    "from neuralpredictors.utils import get_module_output\n",
    "\n",
    "core = Stacked2dCore(input_channels=1,\n",
    "                     hidden_channels=64,\n",
    "                     input_kern=9,\n",
    "                     hidden_kern=7)\n",
    "\n",
    "in_shape_dict = {k: get_module_output(core, in_shape)[1:] for k, in_shape in in_shapes_dict.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Readout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from neuralpredictors.layers.readouts import (\n",
    "    GeneralizedFullGaussianReadout2d,\n",
    "    GeneralizedPointPooled2d,\n",
    "    MultiReadoutBase,\n",
    "    PointPooled2d,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "readout = MultiReadoutBase(in_shape_dict=in_shape_dict,\n",
    "                           n_neurons_dict=n_neurons_dict,\n",
    "                           base_readout=GeneralizedFullGaussianReadout2d,\n",
    "                           bias=True,\n",
    "                           inferred_params_n=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The encoder needs to be implemented by the user, inheriting from the GeneralizedEncoderBase. All the is necessary is to: \n",
    "- provide a list of nonlinearities which makes sure that the parameters predicted by model fulfill the constraints of the respective parameters (for example: the variance of a Gaussian has to be positive -> nonlinearity = Elu1)\n",
    "- a config list of the respective nonlinearities\n",
    "- the method \"predict_mean\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from neuralpredictors.layers.encoders.base import GeneralizedEncoderBase\n",
    "from neuralpredictors.layers.activations import Elu1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GaussianEncoder(GeneralizedEncoderBase):\n",
    "    def __init__(\n",
    "        self,\n",
    "        core,\n",
    "        readout,\n",
    "        eps=1.e-10):\n",
    "        \n",
    "        nonlinearity_type_list = [nn.Identity(), Elu1()]\n",
    "        nonlinearity_config_list = [{}, {\"inplace\": False, \"eps\": eps}]\n",
    "    \n",
    "        super().__init__(core, readout, nonlinearity_type_list, nonlinearity_config_list=nonlinearity_config_list)\n",
    "    \n",
    "    def predict_mean(self, x, *args, data_key=None, **kwargs):\n",
    "        mean, variance = self.forward(x, *args, data_key=data_key, **kwargs)\n",
    "        return mean\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = GaussianEncoder(core, readout)\n",
    "model.to(device);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/neuralpredictors/measures/modules.py:198: UserWarning: Gaussianloss is averaged per batch. It's recommended to use `sum` instead\n",
      "  warnings.warn(\"Gaussianloss is averaged per batch. It's recommended to use `sum` instead\")\n"
     ]
    }
   ],
   "source": [
    "from neuralpredictors.measures.modules import GaussianLoss\n",
    "loss_fn = GaussianLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for images, responses in dataloaders[\"train\"][data_key]:\n",
    "    break\n",
    "\n",
    "output = model(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.4528, device='cuda:0', grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn(target=responses, output=output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part is about how to evaluate your model performance using NInGa. For more info, see [this repo.](https://github.com/sinzlab/lurz_bashiri_iclr2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/sinzlab/lurz_bashiri_iclr2023.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from neuralmetrics.datasets import simulate_neuron_data, simulate_neuron_data_advanced\n",
    "from neuralmetrics.models.utils import get_zig_params_from_moments, get_zil_params_from_moments\n",
    "from neuralmetrics.utils import bits_per_image\n",
    "from neuralmetrics.models.gs_models import Gaussian_GS, Gamma_GS\n",
    "from neuralmetrics.models.gs_zero_inflation import Zero_Inflation_Base\n",
    "from neuralmetrics.models.priors import get_prior_for_gaussian, get_prior_for_q, get_prior_for_gamma, train_prior_for_gaussian\n",
    "from neuralmetrics.models.flows.transforms import Log, Identity\n",
    "from neuralmetrics.models.score_functions import compute_gs_loss_over_target_repeats, compute_null_loss\n",
    "from neuralpredictors.measures.zero_inflated_losses import ZIGLoss, ZILLoss\n",
    "\n",
    "from scipy.stats import beta as beta_distribution\n",
    "\n",
    "from neuralpredictors.measures import corr\n",
    "from neuralpredictors.measures.zero_inflated_losses import ZILLoss\n",
    "\n",
    "\n",
    "random_seed = 27121992\n",
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 100/100 [00:00<00:00, 1309.90it/s]\n",
      "100% 360/360 [00:00<00:00, 10830.38it/s]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(random_seed)\n",
    "\n",
    "exp_data = True\n",
    "n_images = 360\n",
    "n_repeats = 10\n",
    "n_neurons = 100\n",
    "\n",
    "mean = .5\n",
    "variance = .01\n",
    "A = (mean * (1 - mean) / variance - 1)\n",
    "alpha = A * mean\n",
    "beta = A * (1 - mean)\n",
    "zero_inflation_level = beta_distribution(21, 117).rvs(n_neurons)\n",
    "loc = np.exp(-10)\n",
    "\n",
    "resps, gt_means, gt_variances, zil_params = simulate_neuron_data_advanced(n_images=n_images,\n",
    "                                                      n_repeats=n_repeats,\n",
    "                                                      n_neurons=n_neurons,\n",
    "                                                      zero_inflation_level=zero_inflation_level,\n",
    "                                                      loc=loc,\n",
    "                                                      random_state=random_seed)\n",
    "\n",
    "# If single trials are missing due to experimental errors, replace them by np.nan, for example:\n",
    "resps[0, 0, :] = np.nan\n",
    "n_trials = (n_repeats*n_images*n_neurons - np.isnan(resps).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 360, 100)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resps.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize GS model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "loc = np.exp(-10)\n",
    "slab_mask = np.ones_like(resps)\n",
    "slab_mask[resps <= loc] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prior init for zero-inflation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting good init values for q prior parameters...\n"
     ]
    }
   ],
   "source": [
    "print(\"Getting good init values for q prior parameters...\")\n",
    "q_prior_params = get_prior_for_q(torch.from_numpy(resps), loc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prior init for Slab distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting good init values for slab prior parameters...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/neuralmetrics/models/gs_zero_inflation.py:29: UserWarning: Hyperparameter optimization is set to True. Do not forget to recompute the integral over q after each training epoch in the training loop!\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "transform = Identity()\n",
    "resps_transformed, _ = transform(torch.from_numpy(resps) - loc)\n",
    "print(\"Getting good init values for slab prior parameters...\")\n",
    "slab_prior_params = get_prior_for_gamma(resps_transformed.numpy(),\n",
    "                                               per_neuron=False,\n",
    "                                               mask=slab_mask)\n",
    "dist_slab = Gamma_GS(*slab_prior_params, train_prior_hyperparams=True)\n",
    "\n",
    "\n",
    "possible_number_of_loo_repeats = np.unique([dist_slab.get_number_of_repeats(torch.from_numpy(resps[:, i, :])) - 1 for i in range(resps.shape[1])])\n",
    "gs_model = Zero_Inflation_Base(\n",
    "    loc,\n",
    "    dist_slab,\n",
    "    *q_prior_params,\n",
    "    possible_number_of_loo_repeats=possible_number_of_loo_repeats,\n",
    "    transform=transform,\n",
    ").to(device)\n",
    "gs_model.integrals_over_q_dict = gs_model.get_integrals_over_q()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimize prior params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimization takes very long. Interrupted here..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing prior parameters...\n",
      "Loss: -1028400.5000, Epochs: 1\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptimizing prior parameters...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m gs_model, loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_prior_for_gaussian\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgs_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogger\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Optionally save optimized prior params\u001b[39;00m\n\u001b[1;32m      5\u001b[0m prior_params \u001b[38;5;241m=\u001b[39m {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m gs_model\u001b[38;5;241m.\u001b[39mnamed_parameters()}\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/neuralmetrics/models/priors.py:245\u001b[0m, in \u001b[0;36mtrain_prior_for_gaussian\u001b[0;34m(resps, gs_model, use_map, lr, patience, lr_decay_factor, tolerance, verbose, lr_decay_steps, max_iter, logger)\u001b[0m\n\u001b[1;32m    242\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m    243\u001b[0m gs_model\u001b[38;5;241m.\u001b[39mintegrals_over_q_dict \u001b[38;5;241m=\u001b[39m gs_model\u001b[38;5;241m.\u001b[39mget_integrals_over_q()\n\u001b[0;32m--> 245\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_gs_loss_over_target_repeats\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgs_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m logger:\n\u001b[1;32m    248\u001b[0m     wandb\u001b[38;5;241m.\u001b[39mlog({k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m gs_model\u001b[38;5;241m.\u001b[39mnamed_parameters()})\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/neuralmetrics/models/score_functions.py:76\u001b[0m, in \u001b[0;36mcompute_gs_loss_over_target_repeats\u001b[0;34m(resps, gs_model, use_map)\u001b[0m\n\u001b[1;32m     74\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m target_repeat_idx \u001b[38;5;129;01min\u001b[39;00m repeat_indices:\n\u001b[0;32m---> 76\u001b[0m     loss_ \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_gs_loss_over_images\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgs_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_repeat_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m     loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss_\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/neuralmetrics/models/score_functions.py:37\u001b[0m, in \u001b[0;36mcompute_gs_loss_over_images\u001b[0;34m(gs_model, resps, target_repeat_idx, use_map)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39misnan(left_out_response_per_image)\u001b[38;5;241m.\u001b[39msum() \u001b[38;5;241m==\u001b[39m n_neurons:\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misnan\u001b[49m\u001b[43m(\u001b[49m\u001b[43mleft_out_response_per_image\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     38\u001b[0m \n\u001b[1;32m     39\u001b[0m     \u001b[38;5;66;03m# bayesian\u001b[39;00m\n\u001b[1;32m     40\u001b[0m     likelihood, logdet, params \u001b[38;5;241m=\u001b[39m gs_model\u001b[38;5;241m.\u001b[39mposterior_predictive(\n\u001b[1;32m     41\u001b[0m         left_out_response_per_image\u001b[38;5;241m.\u001b[39mto(device), loo_responses_per_image\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     42\u001b[0m     )\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m use_map:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"Optimizing prior parameters...\")\n",
    "gs_model, loss = train_prior_for_gaussian(resps, gs_model, max_iter=200, logger=False, use_map=False)\n",
    "\n",
    "# Optionally save optimized prior params\n",
    "prior_params = {k: v for k, v in gs_model.named_parameters()}\n",
    "# torch.save(prior_params, \"optimized_prior_params\" + \".tar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtain upper and lower bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "params_from_moments_function = get_zig_params_from_moments\n",
    "loss_function = ZIGLoss(per_neuron=True)\n",
    "\n",
    "# Get upper bound log-likelihood per repeat, image and neuron\n",
    "loss_gs = compute_gs_loss_over_target_repeats(resps, gs_model, False).item()\n",
    "upper_bound = -loss_gs / n_trials\n",
    "\n",
    "# Get lower bound log-likelihood per repeat, image and neuron\n",
    "loss_null = compute_null_loss(resps, params_from_moments_function, loss_function, torch.Tensor([loc]).to(device), device).sum()\n",
    "lower_bound = -loss_null / n_trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upper_bound: 2.8836994651292027\n",
      "lower_bound: 2.640894334274279\n"
     ]
    }
   ],
   "source": [
    "print(f\"upper_bound: {upper_bound}\")\n",
    "print(f\"lower_bound: {lower_bound}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
